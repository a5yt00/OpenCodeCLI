{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Qwen Coder - No Tools Mode\n\nStrips tool definitions to force normal text responses."
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup"
            },
            "outputs": [],
            "source": [
                "!nvidia-smi\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudflared-linux-amd64.deb\n",
                "!pip install -q flask requests\n",
                "print('âœ… Setup done')"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "import subprocess, time, os\n",
                "os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
                "os.environ['OLLAMA_ORIGINS'] = '*'\n",
                "subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
                "time.sleep(5)\n",
                "!ollama pull qwen2.5-coder:7b\n",
                "print('\\nâœ… Model ready')"
            ],
            "metadata": {
                "id": "ollama"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# API that strips tools and forces text responses\n",
                "from flask import Flask, request, jsonify\n",
                "import requests as req\n",
                "import json, time, uuid, threading\n",
                "\n",
                "app = Flask(__name__)\n",
                "\n",
                "SYSTEM_PROMPT = \"\"\"You are a helpful coding assistant. \n",
                "IMPORTANT: Always respond with helpful text and code. \n",
                "Never output JSON tool calls. \n",
                "When asked to create files or code, write out the complete code directly.\n",
                "Format code with markdown code blocks.\"\"\"\n",
                "\n",
                "@app.route('/v1/models', methods=['GET'])\n",
                "def models():\n",
                "    return jsonify({\"object\": \"list\", \"data\": [{\"id\": \"qwen2.5-coder:7b\", \"object\": \"model\", \"owned_by\": \"ollama\"}]})\n",
                "\n",
                "@app.route('/v1/chat/completions', methods=['POST'])\n",
                "def chat():\n",
                "    data = request.json\n",
                "    messages = data.get('messages', [])\n",
                "    \n",
                "    # Clean and prepare messages - NO TOOLS\n",
                "    clean_messages = [{'role': 'system', 'content': SYSTEM_PROMPT}]\n",
                "    \n",
                "    for m in messages:\n",
                "        role = m.get('role', 'user')\n",
                "        content = m.get('content', '')\n",
                "        \n",
                "        # Skip system messages (we add our own)\n",
                "        if role == 'system':\n",
                "            continue\n",
                "        # Convert tool messages to user messages\n",
                "        if role == 'tool':\n",
                "            continue\n",
                "        # Skip if no content\n",
                "        if not content or not str(content).strip():\n",
                "            continue\n",
                "            \n",
                "        clean_messages.append({'role': role, 'content': str(content)})\n",
                "    \n",
                "    # Make sure there's at least one user message\n",
                "    if len(clean_messages) == 1:\n",
                "        clean_messages.append({'role': 'user', 'content': 'Hello, can you help me?'})\n",
                "    \n",
                "    # Call Ollama - NO TOOLS PASSED\n",
                "    try:\n",
                "        r = req.post('http://localhost:11434/api/chat', json={\n",
                "            'model': 'qwen2.5-coder:7b',\n",
                "            'messages': clean_messages,\n",
                "            'stream': False,\n",
                "            'options': {'num_ctx': 8192}\n",
                "        }, timeout=120)\n",
                "        \n",
                "        content = r.json().get('message', {}).get('content', '')\n",
                "        if not content:\n",
                "            content = \"I'm ready to help with your coding task. What would you like me to do?\"\n",
                "    except Exception as e:\n",
                "        content = f\"I'm here to help. What code would you like me to write?\"\n",
                "    \n",
                "    return jsonify({\n",
                "        \"id\": f\"chatcmpl-{uuid.uuid4().hex[:12]}\",\n",
                "        \"object\": \"chat.completion\",\n",
                "        \"created\": int(time.time()),\n",
                "        \"model\": \"qwen2.5-coder:7b\",\n",
                "        \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": content}, \"finish_reason\": \"stop\"}],\n",
                "        \"usage\": {\"prompt_tokens\": 50, \"completion_tokens\": 50, \"total_tokens\": 100}\n",
                "    })\n",
                "\n",
                "threading.Thread(target=lambda: app.run(host='0.0.0.0', port=5000, threaded=True, use_reloader=False), daemon=True).start()\n",
                "time.sleep(2)\n",
                "print('âœ… No-Tools API running on port 5000')"
            ],
            "metadata": {
                "id": "api"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Test\n",
                "import requests\n",
                "r = requests.post('http://localhost:5000/v1/chat/completions', json={\n",
                "    'model': 'qwen2.5-coder:7b',\n",
                "    'messages': [{'role': 'user', 'content': 'Write a hello world in Python'}],\n",
                "    'tools': [{'type': 'function', 'function': {'name': 'test'}}]  # Simulating OpenCode sending tools\n",
                "})\n",
                "print(\"Response:\", r.json()['choices'][0]['message']['content'][:300])"
            ],
            "metadata": {
                "id": "test"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Tunnel\n",
                "import subprocess, re\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "tunnel = subprocess.Popen(['cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
                "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')\n",
                "    if 'trycloudflare.com' in line:\n",
                "        m = re.search(r'https://[^\\s]+\\.trycloudflare\\.com', line)\n",
                "        if m:\n",
                "            url = m.group()\n",
                "            display(HTML(f'''<div style=\"background:#e74c3c;padding:25px;border-radius:15px\">\n",
                "            <h2 style=\"color:white\">ðŸš« No-Tools Mode - Text Only</h2>\n",
                "            <p style=\"color:white;font-size:18px;font-family:monospace\">{url}/v1</p>\n",
                "            <p style=\"color:#eee\">Tools stripped - model will respond with text/code only</p>\n",
                "            </div>'''))\n",
                "            break\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')"
            ],
            "metadata": {
                "id": "tunnel"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}