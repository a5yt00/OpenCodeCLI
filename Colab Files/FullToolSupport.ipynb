{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Qwen Coder - Advanced Version\n\nFull-featured coding assistant with smart tool handling."
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup"
            },
            "outputs": [],
            "source": [
                "!nvidia-smi\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudflared-linux-amd64.deb\n",
                "!pip install -q flask requests\n",
                "print('âœ… Setup done')"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "import subprocess, time, os\n",
                "os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
                "os.environ['OLLAMA_ORIGINS'] = '*'\n",
                "subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
                "time.sleep(5)\n",
                "!ollama pull qwen2.5-coder:7b\n",
                "print('\\nâœ… Model ready')"
            ],
            "metadata": {
                "id": "ollama"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from flask import Flask, request, jsonify\n",
                "import requests as req\n",
                "import json, time, uuid, threading, re\n",
                "\n",
                "app = Flask(__name__)\n",
                "\n",
                "SYSTEM_PROMPT = '''You are an elite AI coding assistant with deep expertise across all programming languages, frameworks, and development paradigms.\n",
                "\n",
                "## Core Principles\n",
                "1. **Precision**: Write clean, efficient, production-ready code\n",
                "2. **Best Practices**: Follow industry standards, design patterns, and security principles\n",
                "3. **Clarity**: Explain complex concepts simply when asked\n",
                "4. **Efficiency**: Solve problems with minimal, elegant solutions\n",
                "\n",
                "## Response Guidelines\n",
                "- For **greetings/questions**: Respond conversationally - do NOT use tools\n",
                "- For **code requests**: Write complete, working code with proper error handling\n",
                "- For **file operations**: Use the appropriate tool (write, edit, read)\n",
                "- For **debugging**: Analyze systematically, identify root causes\n",
                "- For **architecture**: Consider scalability, maintainability, security\n",
                "\n",
                "## Code Style\n",
                "- Use meaningful variable/function names\n",
                "- Add concise comments for complex logic\n",
                "- Handle edge cases and errors gracefully\n",
                "- Follow language-specific conventions (PEP8 for Python, ESLint for JS, etc)\n",
                "\n",
                "## Tool Usage Rules\n",
                "- ONLY use tools when the user explicitly requests an action (create, edit, read, run, search)\n",
                "- For simple conversations or code explanations, respond with text only\n",
                "- When using tools, provide the exact required arguments\n",
                "- Never invent tool names - only use tools from the provided list\n",
                "\n",
                "## Expertise Areas\n",
                "- Full-stack development (React, Node, Python, Go, Rust)\n",
                "- DevOps & Cloud (Docker, K8s, AWS, GCP, Azure)\n",
                "- Databases (SQL, NoSQL, Graph, Vector)\n",
                "- AI/ML (PyTorch, TensorFlow, LangChain, RAG)\n",
                "- Security (OWASP, encryption, auth patterns)\n",
                "- Performance optimization & debugging\n",
                "\n",
                "Be concise, accurate, and helpful. Focus on solving the user\\'s problem efficiently.'''\n",
                "\n",
                "def needs_tools(user_msg):\n",
                "    msg = user_msg.lower()\n",
                "    # Action keywords that indicate tool usage\n",
                "    action_kw = ['create', 'write', 'make', 'generate', 'add', 'new',\n",
                "                 'edit', 'modify', 'update', 'change', 'fix', 'refactor',\n",
                "                 'delete', 'remove', 'read', 'open', 'show', 'view', 'list',\n",
                "                 'run', 'execute', 'test', 'build', 'deploy',\n",
                "                 'search', 'find', 'grep', 'locate',\n",
                "                 'file', 'folder', 'directory', 'project',\n",
                "                 'todo', 'task', 'bash', 'terminal', 'command', 'script']\n",
                "    return any(kw in msg for kw in action_kw)\n",
                "\n",
                "def get_tool_names(tools):\n",
                "    names = set()\n",
                "    for t in tools or []:\n",
                "        if t.get('type') == 'function' and 'function' in t:\n",
                "            names.add(t['function'].get('name', ''))\n",
                "    return names\n",
                "\n",
                "def extract_tool_call(text, valid_tools):\n",
                "    if not text or not valid_tools:\n",
                "        return None\n",
                "    \n",
                "    # Code blocks first\n",
                "    code_block = re.search(r'```(?:json)?\\s*([\\s\\S]*?)```', text)\n",
                "    if code_block:\n",
                "        try:\n",
                "            data = json.loads(code_block.group(1).strip())\n",
                "            name = data.get('name', '')\n",
                "            if name in valid_tools:\n",
                "                return name, json.dumps(data.get('arguments', {}))\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    # Inline JSON\n",
                "    match = re.search(r'\\{[\\s\\S]*?\"name\"\\s*:\\s*\"([^\"]+)\"[\\s\\S]*?\"arguments\"\\s*:\\s*(\\{[^{}]*\\})', text)\n",
                "    if match and match.group(1) in valid_tools:\n",
                "        return match.group(1), match.group(2)\n",
                "    \n",
                "    return None\n",
                "\n",
                "@app.route('/v1/models', methods=['GET'])\n",
                "def models():\n",
                "    return jsonify({\"object\": \"list\", \"data\": [{\"id\": \"qwen2.5-coder:7b\", \"object\": \"model\", \"owned_by\": \"ollama\"}]})\n",
                "\n",
                "@app.route('/v1/chat/completions', methods=['POST'])\n",
                "def chat():\n",
                "    data = request.json\n",
                "    messages = data.get('messages', [])\n",
                "    tools = data.get('tools', [])\n",
                "    valid_tools = get_tool_names(tools)\n",
                "    \n",
                "    # Get last user message\n",
                "    last_user_msg = ''\n",
                "    for m in reversed(messages):\n",
                "        if m.get('role') == 'user' and m.get('content'):\n",
                "            last_user_msg = str(m.get('content', ''))\n",
                "            break\n",
                "    \n",
                "    use_tools = needs_tools(last_user_msg)\n",
                "    print(f\"[{time.strftime('%H:%M:%S')}] '{last_user_msg[:40]}...' tools={use_tools}\")\n",
                "    \n",
                "    # Build messages with system prompt\n",
                "    modified_messages = [{'role': 'system', 'content': SYSTEM_PROMPT}]\n",
                "    for m in messages:\n",
                "        if m.get('role') != 'system':\n",
                "            modified_messages.append(m)\n",
                "    \n",
                "    # Call Ollama\n",
                "    try:\n",
                "        payload = {\n",
                "            'model': 'qwen2.5-coder:7b',\n",
                "            'messages': modified_messages,\n",
                "            'stream': False,\n",
                "            'options': {'num_ctx': 16384}\n",
                "        }\n",
                "        if use_tools and tools:\n",
                "            payload['tools'] = tools\n",
                "        \n",
                "        r = req.post('http://localhost:11434/v1/chat/completions', json=payload, timeout=180)\n",
                "        result = r.json()\n",
                "        msg = result.get('choices', [{}])[0].get('message', {})\n",
                "        content = msg.get('content', '')\n",
                "        tool_calls = msg.get('tool_calls', [])\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        content = \"I'm here to help! What would you like to work on today?\"\n",
                "        tool_calls = []\n",
                "    \n",
                "    # Ollama returned tool calls\n",
                "    if tool_calls:\n",
                "        print(f\"  â†’ Tool calls from Ollama\")\n",
                "        return jsonify({\n",
                "            \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "            \"object\": \"chat.completion\",\n",
                "            \"created\": int(time.time()),\n",
                "            \"model\": \"qwen2.5-coder:7b\",\n",
                "            \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": None, \"tool_calls\": tool_calls}, \"finish_reason\": \"tool_calls\"}],\n",
                "            \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": 100, \"total_tokens\": 200}\n",
                "        })\n",
                "    \n",
                "    # Parse tool calls from text if needed\n",
                "    if use_tools and valid_tools and content:\n",
                "        tool_result = extract_tool_call(content, valid_tools)\n",
                "        if tool_result:\n",
                "            name, args = tool_result\n",
                "            print(f\"  â†’ Parsed tool: {name}\")\n",
                "            return jsonify({\n",
                "                \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "                \"object\": \"chat.completion\",\n",
                "                \"created\": int(time.time()),\n",
                "                \"model\": \"qwen2.5-coder:7b\",\n",
                "                \"choices\": [{\n",
                "                    \"index\": 0,\n",
                "                    \"message\": {\n",
                "                        \"role\": \"assistant\",\n",
                "                        \"content\": None,\n",
                "                        \"tool_calls\": [{\n",
                "                            \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
                "                            \"type\": \"function\",\n",
                "                            \"function\": {\"name\": name, \"arguments\": args}\n",
                "                        }]\n",
                "                    },\n",
                "                    \"finish_reason\": \"tool_calls\"\n",
                "                }],\n",
                "                \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": 100, \"total_tokens\": 200}\n",
                "            })\n",
                "    \n",
                "    # Clean up and return text\n",
                "    if content:\n",
                "        content = re.sub(r'```json[\\s\\S]*?```', '', content).strip()\n",
                "        content = re.sub(r'\\{\\s*\"name\"[^}]+\\}', '', content).strip()\n",
                "    if not content:\n",
                "        content = \"Hello! I'm your coding assistant. How can I help you today?\"\n",
                "    \n",
                "    print(f\"  â†’ Text response ({len(content)} chars)\")\n",
                "    return jsonify({\n",
                "        \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "        \"object\": \"chat.completion\",\n",
                "        \"created\": int(time.time()),\n",
                "        \"model\": \"qwen2.5-coder:7b\",\n",
                "        \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": content}, \"finish_reason\": \"stop\"}],\n",
                "        \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": len(content.split()), \"total_tokens\": 100 + len(content.split())}\n",
                "    })\n",
                "\n",
                "@app.route('/health', methods=['GET'])\n",
                "def health():\n",
                "    return jsonify({\"status\": \"healthy\", \"model\": \"qwen2.5-coder:7b\"})\n",
                "\n",
                "threading.Thread(target=lambda: app.run(host='0.0.0.0', port=5000, threaded=True, use_reloader=False), daemon=True).start()\n",
                "time.sleep(2)\n",
                "print('âœ… Advanced API running on port 5000!')"
            ],
            "metadata": {
                "id": "api"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Test\n",
                "import requests\n",
                "\n",
                "tests = [\n",
                "    (\"Hi\", False),\n",
                "    (\"What is Python?\", False),\n",
                "    (\"Create a file test.py\", True),\n",
                "    (\"Write a sorting algorithm\", True),\n",
                "]\n",
                "\n",
                "for msg, expect_tools in tests:\n",
                "    r = requests.post('http://localhost:5000/v1/chat/completions', json={\n",
                "        'model': 'qwen2.5-coder:7b',\n",
                "        'messages': [{'role': 'user', 'content': msg}],\n",
                "        'tools': [{'type': 'function', 'function': {'name': 'write'}}]\n",
                "    })\n",
                "    has_tools = r.json()['choices'][0].get('message', {}).get('tool_calls') is not None\n",
                "    status = 'âœ…' if has_tools == expect_tools else 'âš ï¸'\n",
                "    print(f\"{status} '{msg}' -> tools={has_tools} (expected {expect_tools})\")"
            ],
            "metadata": {
                "id": "test"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import subprocess, re\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "tunnel = subprocess.Popen(['cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
                "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')\n",
                "    if 'trycloudflare.com' in line:\n",
                "        m = re.search(r'https://[^\\s]+\\.trycloudflare\\.com', line)\n",
                "        if m:\n",
                "            url = m.group()\n",
                "            display(HTML(f'''<div style=\"background:linear-gradient(135deg,#667eea,#764ba2);padding:30px;border-radius:20px\">\n",
                "            <h2 style=\"color:white;margin:0\">ðŸš€ Elite Coding Assistant Ready</h2>\n",
                "            <p style=\"color:white;font-size:20px;font-family:monospace;margin:15px 0\">{url}/v1</p>\n",
                "            <p style=\"color:#ddd;margin:0\">Advanced prompt â€¢ Smart tool detection â€¢ Production-ready</p>\n",
                "            </div>'''))\n",
                "            break\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')"
            ],
            "metadata": {
                "id": "tunnel"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}