{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# ğŸš€ Universal LLM Server for OpenCode\n\n**Change the MODEL variable below to use any Ollama model.**\n\nRecommended models:\n- `deepseek-coder-v2:16b` - Best coding (current)\n- `qwen2.5-coder:7b` - Fast, good coding\n- `codellama:13b` - Code generation\n- `mistral:7b` - General purpose"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "config"
            },
            "outputs": [],
            "source": [
                "#@title âš™ï¸ Configuration\n",
                "MODEL = \"deepseek-coder-v2:16b\"  #@param {type:\"string\"}\n",
                "print(f\"ğŸ“¦ Selected model: {MODEL}\")"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ğŸ“¥ Install Dependencies\n",
                "!nvidia-smi\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudflared-linux-amd64.deb\n",
                "!pip install -q flask requests\n",
                "print('\\nâœ… Dependencies installed')"
            ],
            "metadata": {
                "id": "setup"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ğŸ¤– Start Ollama & Download Model\n",
                "import subprocess, time, os\n",
                "os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
                "os.environ['OLLAMA_ORIGINS'] = '*'\n",
                "subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
                "time.sleep(5)\n",
                "print(f'Downloading {MODEL}... (this may take a while)')\n",
                "!ollama pull {MODEL}\n",
                "print(f'\\nâœ… {MODEL} ready!')"
            ],
            "metadata": {
                "id": "ollama"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ğŸ”§ OpenCode-Compatible API Server\n",
                "from flask import Flask, request, jsonify\n",
                "import requests as req\n",
                "import json, time, uuid, threading, re\n",
                "\n",
                "app = Flask(__name__)\n",
                "\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# SYSTEM PROMPT - Elite Coding Assistant\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "SYSTEM_PROMPT = '''You are an elite AI coding assistant. You are precise, efficient, and follow best practices.\n",
                "\n",
                "## How to Respond\n",
                "\n",
                "### For Greetings & Questions (NO tools)\n",
                "- Respond naturally and helpfully\n",
                "- Be concise but informative\n",
                "- Provide code examples in markdown when helpful\n",
                "\n",
                "### For File Operations (USE tools)\n",
                "When asked to create, edit, read, or write files, use the provided tools.\n",
                "Format tool calls as JSON:\n",
                "```json\n",
                "{\"name\": \"tool_name\", \"arguments\": {\"param\": \"value\"}}\n",
                "```\n",
                "\n",
                "## Code Standards\n",
                "- Write clean, production-ready code\n",
                "- Use meaningful names and add comments for complex logic\n",
                "- Handle errors properly\n",
                "- Follow language conventions (PEP8, ESLint, etc)\n",
                "\n",
                "## Important Rules\n",
                "1. ONLY use tools when explicitly asked to perform file/system operations\n",
                "2. For questions about code, respond with explanations and examples\n",
                "3. Be concise - don't over-explain\n",
                "4. If unsure, ask for clarification'''\n",
                "\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# Helper Functions\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "def needs_tools(msg):\n",
                "    \"\"\"Detect if message requires tool usage.\"\"\"\n",
                "    m = msg.lower()\n",
                "    actions = ['create', 'write', 'make', 'generate', 'add', 'new', 'save',\n",
                "               'edit', 'modify', 'update', 'change', 'fix', 'refactor', 'rename',\n",
                "               'delete', 'remove', 'read', 'open', 'show file', 'cat ', 'view file',\n",
                "               'run', 'execute', 'test', 'build', 'deploy', 'install',\n",
                "               'search', 'find', 'grep', 'locate', 'list files',\n",
                "               'file', 'folder', 'directory', 'path',\n",
                "               'todo', 'task', 'bash', 'terminal', 'command', 'shell']\n",
                "    return any(a in m for a in actions)\n",
                "\n",
                "def get_valid_tools(tools):\n",
                "    \"\"\"Extract tool names from definitions.\"\"\"\n",
                "    return {t['function']['name'] for t in tools or [] if t.get('type') == 'function' and 'function' in t}\n",
                "\n",
                "def extract_tool(text, valid):\n",
                "    \"\"\"Extract tool call from response text.\"\"\"\n",
                "    if not text or not valid:\n",
                "        return None\n",
                "    \n",
                "    # Try code block\n",
                "    m = re.search(r'```(?:json)?\\s*([\\s\\S]*?)```', text)\n",
                "    if m:\n",
                "        try:\n",
                "            d = json.loads(m.group(1).strip())\n",
                "            if d.get('name') in valid:\n",
                "                return d['name'], json.dumps(d.get('arguments', {}))\n",
                "        except: pass\n",
                "    \n",
                "    # Try inline\n",
                "    m = re.search(r'\\{[^{}]*\"name\"\\s*:\\s*\"([^\"]+)\"[^{}]*\"arguments\"\\s*:\\s*(\\{[^{}]*\\})', text)\n",
                "    if m and m.group(1) in valid:\n",
                "        return m.group(1), m.group(2)\n",
                "    \n",
                "    return None\n",
                "\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# API Routes\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "@app.route('/v1/models', methods=['GET'])\n",
                "def list_models():\n",
                "    return jsonify({\"object\": \"list\", \"data\": [{\"id\": MODEL, \"object\": \"model\", \"owned_by\": \"ollama\"}]})\n",
                "\n",
                "@app.route('/v1/chat/completions', methods=['POST'])\n",
                "def chat():\n",
                "    data = request.json\n",
                "    messages = data.get('messages', [])\n",
                "    tools = data.get('tools', [])\n",
                "    valid_tools = get_valid_tools(tools)\n",
                "    \n",
                "    # Get last user message\n",
                "    user_msg = next((m['content'] for m in reversed(messages) if m.get('role') == 'user' and m.get('content')), '')\n",
                "    use_tools = needs_tools(str(user_msg))\n",
                "    \n",
                "    print(f\"[{time.strftime('%H:%M:%S')}] '{str(user_msg)[:50]}' tools={use_tools}\")\n",
                "    \n",
                "    # Add system prompt\n",
                "    msgs = [{'role': 'system', 'content': SYSTEM_PROMPT}]\n",
                "    msgs.extend(m for m in messages if m.get('role') != 'system')\n",
                "    \n",
                "    # Call Ollama\n",
                "    try:\n",
                "        payload = {'model': MODEL, 'messages': msgs, 'stream': False, 'options': {'num_ctx': 16384}}\n",
                "        if use_tools and tools:\n",
                "            payload['tools'] = tools\n",
                "        \n",
                "        r = req.post('http://localhost:11434/v1/chat/completions', json=payload, timeout=300)\n",
                "        result = r.json()\n",
                "        msg = result.get('choices', [{}])[0].get('message', {})\n",
                "        content = msg.get('content', '')\n",
                "        tool_calls = msg.get('tool_calls', [])\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        content = \"I'm ready to help! What would you like to code?\"\n",
                "        tool_calls = []\n",
                "    \n",
                "    # Return tool calls if present\n",
                "    if tool_calls:\n",
                "        print(f\"  â†’ Native tool calls\")\n",
                "        return jsonify({\n",
                "            \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "            \"object\": \"chat.completion\",\n",
                "            \"created\": int(time.time()),\n",
                "            \"model\": MODEL,\n",
                "            \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": None, \"tool_calls\": tool_calls}, \"finish_reason\": \"tool_calls\"}],\n",
                "            \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": 100, \"total_tokens\": 200}\n",
                "        })\n",
                "    \n",
                "    # Try to extract tool from text\n",
                "    if use_tools and valid_tools and content:\n",
                "        tool = extract_tool(content, valid_tools)\n",
                "        if tool:\n",
                "            name, args = tool\n",
                "            print(f\"  â†’ Extracted tool: {name}\")\n",
                "            return jsonify({\n",
                "                \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "                \"object\": \"chat.completion\",\n",
                "                \"created\": int(time.time()),\n",
                "                \"model\": MODEL,\n",
                "                \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": None, \"tool_calls\": [{\"id\": f\"call_{uuid.uuid4().hex[:8]}\", \"type\": \"function\", \"function\": {\"name\": name, \"arguments\": args}}]}, \"finish_reason\": \"tool_calls\"}],\n",
                "                \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": 100, \"total_tokens\": 200}\n",
                "            })\n",
                "    \n",
                "    # Clean and return text\n",
                "    if content:\n",
                "        content = re.sub(r'```json\\s*\\{[^`]*\"name\"[^`]*\\}\\s*```', '', content).strip()\n",
                "    if not content:\n",
                "        content = \"Hello! I'm ready to assist with your coding tasks.\"\n",
                "    \n",
                "    print(f\"  â†’ Text ({len(content)} chars)\")\n",
                "    return jsonify({\n",
                "        \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "        \"object\": \"chat.completion\",\n",
                "        \"created\": int(time.time()),\n",
                "        \"model\": MODEL,\n",
                "        \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": content}, \"finish_reason\": \"stop\"}],\n",
                "        \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": len(content.split()), \"total_tokens\": 100 + len(content.split())}\n",
                "    })\n",
                "\n",
                "@app.route('/health', methods=['GET'])\n",
                "def health():\n",
                "    return jsonify({\"status\": \"ok\", \"model\": MODEL})\n",
                "\n",
                "# Start server\n",
                "threading.Thread(target=lambda: app.run(host='0.0.0.0', port=5000, threaded=True, use_reloader=False), daemon=True).start()\n",
                "time.sleep(2)\n",
                "print(f'\\nâœ… API Server running with {MODEL}')"
            ],
            "metadata": {
                "id": "api"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ğŸ§ª Test API\n",
                "import requests\n",
                "\n",
                "tests = [\n",
                "    (\"Hi there!\", \"No tools\"),\n",
                "    (\"What is Python?\", \"No tools\"),\n",
                "    (\"Create a file test.py\", \"Should use tools\"),\n",
                "]\n",
                "\n",
                "for msg, expected in tests:\n",
                "    r = requests.post('http://localhost:5000/v1/chat/completions', json={\n",
                "        'model': MODEL,\n",
                "        'messages': [{'role': 'user', 'content': msg}],\n",
                "        'tools': [{'type': 'function', 'function': {'name': 'write', 'parameters': {}}}]\n",
                "    }, timeout=120)\n",
                "    resp = r.json()['choices'][0]['message']\n",
                "    has_tools = resp.get('tool_calls') is not None\n",
                "    print(f\"'{msg}' â†’ {'ğŸ”§ Tools' if has_tools else 'ğŸ’¬ Text'} ({expected})\")"
            ],
            "metadata": {
                "id": "test"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ğŸŒ Start Cloudflare Tunnel\n",
                "import subprocess, re\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "tunnel = subprocess.Popen(['cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
                "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')\n",
                "    if 'trycloudflare.com' in line:\n",
                "        m = re.search(r'https://[^\\s]+\\.trycloudflare\\.com', line)\n",
                "        if m:\n",
                "            url = m.group()\n",
                "            display(HTML(f'''\n",
                "            <div style=\"background:linear-gradient(135deg,#00b894,#00cec9);padding:30px;border-radius:20px;margin:20px 0\">\n",
                "                <h2 style=\"color:white;margin:0 0 15px 0\">ğŸš€ {MODEL} Ready!</h2>\n",
                "                <p style=\"color:white;font-size:22px;font-family:monospace;background:rgba(0,0,0,0.2);padding:15px;border-radius:10px;margin:0\">{url}/v1</p>\n",
                "                <hr style=\"border:none;border-top:1px solid rgba(255,255,255,0.3);margin:20px 0\">\n",
                "                <p style=\"color:white;margin:5px 0\"><b>OpenCode Setup:</b></p>\n",
                "                <p style=\"color:#e0e0e0;margin:5px 0\">Settings â†’ Custom Provider â†’ Base URL: <code>{url}/v1</code></p>\n",
                "                <p style=\"color:#e0e0e0;margin:5px 0\">Model: <code>{MODEL}</code></p>\n",
                "            </div>\n",
                "            '''))\n",
                "            break\n",
                "\n",
                "print('\\nâš ï¸ Keep this cell running!')\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')"
            ],
            "metadata": {
                "id": "tunnel"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}