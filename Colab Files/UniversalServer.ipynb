{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üöÄ Universal OpenCode Server\n\n**Works with Qwen, DeepSeek, and other models.**\n\nThis server translates model responses into proper tool calls that OpenCode can execute."
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "config"
            },
            "outputs": [],
            "source": [
                "#@title ‚öôÔ∏è Configuration\n",
                "#@markdown Choose your model:\n",
                "MODEL = \"qwen2.5-coder:7b\"  #@param [\"qwen2.5-coder:7b\", \"deepseek-coder-v2:16b\", \"codellama:13b\", \"mistral:7b\"]\n",
                "print(f\"üì¶ Model: {MODEL}\")"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üì• Install Dependencies\n",
                "!nvidia-smi\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudflared-linux-amd64.deb\n",
                "!pip install -q flask requests\n",
                "print('\\n‚úÖ Dependencies installed')"
            ],
            "metadata": {
                "id": "setup"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ü§ñ Start Ollama & Download Model\n",
                "import subprocess, time, os\n",
                "os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
                "os.environ['OLLAMA_ORIGINS'] = '*'\n",
                "subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
                "time.sleep(5)\n",
                "print(f'Downloading {MODEL}...')\n",
                "!ollama pull {MODEL}\n",
                "print(f'\\n‚úÖ {MODEL} ready!')"
            ],
            "metadata": {
                "id": "model"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üîß OpenCode Compatible API Server\n",
                "from flask import Flask, request, jsonify\n",
                "import requests as req\n",
                "import json, time, uuid, threading, re\n",
                "\n",
                "app = Flask(__name__)\n",
                "\n",
                "# System prompt that teaches the model to output tool calls as JSON\n",
                "SYSTEM_PROMPT = '''You are an expert coding assistant with access to tools.\n",
                "\n",
                "## CRITICAL: Tool Usage Format\n",
                "When you need to create files, run commands, or perform actions, you MUST output a tool call as JSON.\n",
                "\n",
                "Available tools:\n",
                "- file_write: Create or write a file. Args: path, content\n",
                "- file_read: Read a file. Args: path\n",
                "- shell: Run a command. Args: command\n",
                "- list_files: List directory contents. Args: path (optional)\n",
                "- search: Search for text in files. Args: pattern, path (optional)\n",
                "\n",
                "## Tool Call Format\n",
                "When using a tool, respond with ONLY this JSON block (no other text before or after):\n",
                "```json\n",
                "{\"name\": \"tool_name\", \"arguments\": {\"arg1\": \"value1\"}}\n",
                "```\n",
                "\n",
                "## Examples\n",
                "\n",
                "User: \"Create a hello world Python script\"\n",
                "```json\n",
                "{\"name\": \"file_write\", \"arguments\": {\"path\": \"hello.py\", \"content\": \"print('Hello, World!')\"}}\n",
                "```\n",
                "\n",
                "User: \"Run the script\"\n",
                "```json\n",
                "{\"name\": \"shell\", \"arguments\": {\"command\": \"python hello.py\"}}\n",
                "```\n",
                "\n",
                "User: \"What files are in this folder?\"\n",
                "```json\n",
                "{\"name\": \"list_files\", \"arguments\": {}}\n",
                "```\n",
                "\n",
                "User: \"Find all TODO comments\"\n",
                "```json\n",
                "{\"name\": \"search\", \"arguments\": {\"pattern\": \"TODO\"}}\n",
                "```\n",
                "\n",
                "## When NOT to use tools\n",
                "- For greetings (\"Hi\", \"Hello\") - respond with friendly text\n",
                "- For questions about code - explain with text and code examples\n",
                "- For help/documentation - provide helpful explanations\n",
                "\n",
                "Be precise, helpful, and efficient.'''\n",
                "\n",
                "# Custom tools that we support\n",
                "CUSTOM_TOOLS = {'file_write', 'file_read', 'shell', 'list_files', 'search'}\n",
                "\n",
                "def needs_tools(msg):\n",
                "    \"\"\"Check if the message needs tool execution.\"\"\"\n",
                "    m = msg.lower() if msg else ''\n",
                "    actions = ['create', 'write', 'make', 'generate', 'new', 'save', 'add',\n",
                "               'edit', 'modify', 'update', 'change', 'fix', 'refactor',\n",
                "               'delete', 'remove', 'run', 'execute', 'test', 'build',\n",
                "               'read', 'open', 'show', 'list', 'find', 'search', 'grep',\n",
                "               'file', 'script', 'code', 'folder', 'directory']\n",
                "    return any(a in m for a in actions)\n",
                "\n",
                "def extract_tool(text):\n",
                "    \"\"\"Extract tool call from model response.\"\"\"\n",
                "    if not text:\n",
                "        return None\n",
                "    \n",
                "    # Try JSON in code block\n",
                "    m = re.search(r'```(?:json)?\\s*([\\s\\S]*?)```', text)\n",
                "    if m:\n",
                "        try:\n",
                "            d = json.loads(m.group(1).strip())\n",
                "            if 'name' in d:\n",
                "                return d['name'], json.dumps(d.get('arguments', {}))\n",
                "        except: pass\n",
                "    \n",
                "    # Try raw JSON\n",
                "    m = re.search(r'\\{\\s*\"name\"\\s*:\\s*\"([^\"]+)\"\\s*,\\s*\"arguments\"\\s*:\\s*(\\{[^{}]*\\})', text)\n",
                "    if m:\n",
                "        return m.group(1), m.group(2)\n",
                "    \n",
                "    return None\n",
                "\n",
                "@app.route('/v1/models', methods=['GET'])\n",
                "def list_models():\n",
                "    return jsonify({\"object\": \"list\", \"data\": [{\"id\": MODEL, \"object\": \"model\", \"owned_by\": \"ollama\"}]})\n",
                "\n",
                "@app.route('/v1/chat/completions', methods=['POST'])\n",
                "def chat():\n",
                "    data = request.json\n",
                "    messages = data.get('messages', [])\n",
                "    \n",
                "    # Get last user message\n",
                "    user_msg = ''\n",
                "    for m in reversed(messages):\n",
                "        if m.get('role') == 'user' and m.get('content'):\n",
                "            user_msg = str(m['content'])\n",
                "            break\n",
                "    \n",
                "    use_tools = needs_tools(user_msg)\n",
                "    print(f\"[{time.strftime('%H:%M:%S')}] '{user_msg[:50]}' tools={use_tools}\")\n",
                "    \n",
                "    # Build messages with system prompt\n",
                "    msgs = [{'role': 'system', 'content': SYSTEM_PROMPT}]\n",
                "    for m in messages:\n",
                "        if m.get('role') != 'system':\n",
                "            msgs.append(m)\n",
                "    \n",
                "    # Call Ollama\n",
                "    try:\n",
                "        r = req.post('http://localhost:11434/api/chat', json={\n",
                "            'model': MODEL,\n",
                "            'messages': msgs,\n",
                "            'stream': False,\n",
                "            'options': {'num_ctx': 8192}\n",
                "        }, timeout=180)\n",
                "        content = r.json().get('message', {}).get('content', '')\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        content = \"I'm ready to help! What would you like me to do?\"\n",
                "    \n",
                "    # Try to extract tool call\n",
                "    if use_tools and content:\n",
                "        tool = extract_tool(content)\n",
                "        if tool:\n",
                "            name, args = tool\n",
                "            print(f\"  ‚Üí Tool: {name}\")\n",
                "            return jsonify({\n",
                "                \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "                \"object\": \"chat.completion\",\n",
                "                \"created\": int(time.time()),\n",
                "                \"model\": MODEL,\n",
                "                \"choices\": [{\n",
                "                    \"index\": 0,\n",
                "                    \"message\": {\n",
                "                        \"role\": \"assistant\",\n",
                "                        \"content\": None,\n",
                "                        \"tool_calls\": [{\n",
                "                            \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
                "                            \"type\": \"function\",\n",
                "                            \"function\": {\"name\": name, \"arguments\": args}\n",
                "                        }]\n",
                "                    },\n",
                "                    \"finish_reason\": \"tool_calls\"\n",
                "                }],\n",
                "                \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": 50, \"total_tokens\": 150}\n",
                "            })\n",
                "    \n",
                "    # Clean and return text\n",
                "    if content:\n",
                "        # Remove any JSON blocks that we couldn't parse\n",
                "        content = re.sub(r'```json[\\s\\S]*?```', '', content).strip()\n",
                "        content = re.sub(r'\\{\\s*\"name\"[^}]+\\}', '', content).strip()\n",
                "    if not content:\n",
                "        content = \"Hello! I'm ready to help with your coding tasks.\"\n",
                "    \n",
                "    print(f\"  ‚Üí Text ({len(content)} chars)\")\n",
                "    return jsonify({\n",
                "        \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "        \"object\": \"chat.completion\",\n",
                "        \"created\": int(time.time()),\n",
                "        \"model\": MODEL,\n",
                "        \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": content}, \"finish_reason\": \"stop\"}],\n",
                "        \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": len(content.split()), \"total_tokens\": 100 + len(content.split())}\n",
                "    })\n",
                "\n",
                "@app.route('/health', methods=['GET'])\n",
                "def health():\n",
                "    return jsonify({\"status\": \"ok\", \"model\": MODEL})\n",
                "\n",
                "# Start server\n",
                "threading.Thread(target=lambda: app.run(host='0.0.0.0', port=5000, threaded=True, use_reloader=False), daemon=True).start()\n",
                "time.sleep(2)\n",
                "print(f'\\n‚úÖ API Server ready with {MODEL}')"
            ],
            "metadata": {
                "id": "api"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üß™ Test Tool Calling\n",
                "import requests\n",
                "\n",
                "print(\"Test 1: Create a file (should use tool)\")\n",
                "r = requests.post('http://localhost:5000/v1/chat/completions', json={\n",
                "    'model': MODEL,\n",
                "    'messages': [{'role': 'user', 'content': 'Create a Python file hello.py that prints Hello World'}]\n",
                "}, timeout=120)\n",
                "resp = r.json()['choices'][0]\n",
                "if resp['message'].get('tool_calls'):\n",
                "    tc = resp['message']['tool_calls'][0]['function']\n",
                "    print(f\"  ‚úÖ Tool call: {tc['name']}\")\n",
                "    print(f\"     Args: {tc['arguments'][:100]}...\")\n",
                "else:\n",
                "    print(f\"  ‚ö†Ô∏è Text response: {resp['message'].get('content', '')[:100]}...\")\n",
                "\n",
                "print(\"\\nTest 2: Simple greeting (should return text)\")\n",
                "r = requests.post('http://localhost:5000/v1/chat/completions', json={\n",
                "    'model': MODEL,\n",
                "    'messages': [{'role': 'user', 'content': 'Hi there!'}]\n",
                "}, timeout=120)\n",
                "resp = r.json()['choices'][0]\n",
                "if resp['message'].get('content'):\n",
                "    print(f\"  ‚úÖ Text: {resp['message']['content'][:80]}...\")\n",
                "else:\n",
                "    print(f\"  ‚ö†Ô∏è Got tool call instead\")"
            ],
            "metadata": {
                "id": "test"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üåê Start Tunnel\n",
                "import subprocess, re\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "tunnel = subprocess.Popen(['cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
                "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')\n",
                "    if 'trycloudflare.com' in line:\n",
                "        m = re.search(r'https://[^\\s]+\\.trycloudflare\\.com', line)\n",
                "        if m:\n",
                "            url = m.group()\n",
                "            display(HTML(f'''\n",
                "            <div style=\"background:linear-gradient(135deg,#00b894,#00cec9);padding:30px;border-radius:20px\">\n",
                "                <h2 style=\"color:white;margin:0\">üöÄ OpenCode Server Ready!</h2>\n",
                "                <p style=\"color:white;font-size:22px;font-family:monospace;margin:15px 0\">{url}/v1</p>\n",
                "                <hr style=\"border:none;border-top:1px solid rgba(255,255,255,0.3);margin:20px 0\">\n",
                "                <p style=\"color:white\"><b>Model:</b> {MODEL}</p>\n",
                "                <p style=\"color:white\"><b>Custom Tools:</b> file_write, file_read, shell, list_files, search</p>\n",
                "            </div>\n",
                "            '''))\n",
                "            break\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')"
            ],
            "metadata": {
                "id": "tunnel"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}