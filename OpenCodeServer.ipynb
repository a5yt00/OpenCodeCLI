{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üîß OpenCode Compatible LLM Server\n\n**Uses Qwen 2.5 Coder - the ONLY Ollama model with reliable tool support.**\n\n> ‚ö†Ô∏è DeepSeek, Mistral, CodeLlama do NOT properly support function calling through Ollama."
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup"
            },
            "outputs": [],
            "source": [
                "#@title üì• Install\n",
                "!nvidia-smi\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudflared-linux-amd64.deb\n",
                "!pip install -q flask requests\n",
                "print('‚úÖ Ready')"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ü§ñ Start Model\n",
                "import subprocess, time, os\n",
                "os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
                "os.environ['OLLAMA_ORIGINS'] = '*'\n",
                "subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
                "time.sleep(5)\n",
                "# Qwen is the only model with reliable tool support\n",
                "!ollama pull qwen2.5-coder:7b\n",
                "print('\\n‚úÖ Model ready')"
            ],
            "metadata": {
                "id": "model"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üöÄ API Server (With Forced Tool Output)\n",
                "from flask import Flask, request, jsonify\n",
                "import requests as req\n",
                "import json, time, uuid, threading, re\n",
                "\n",
                "app = Flask(__name__)\n",
                "MODEL = \"qwen2.5-coder:7b\"\n",
                "\n",
                "# Force tool usage for action requests\n",
                "TOOL_PROMPT = '''You are an AI coding assistant that uses tools to complete tasks.\n",
                "\n",
                "## CRITICAL: When to use tools\n",
                "For ANY request to create, edit, write, or modify files - you MUST respond with a tool call.\n",
                "\n",
                "## Tool Call Format\n",
                "When using a tool, respond ONLY with this JSON (no other text):\n",
                "```json\n",
                "{\"name\": \"tool_name\", \"arguments\": {\"param\": \"value\"}}\n",
                "```\n",
                "\n",
                "## Available Tools\n",
                "- write: Write content to a file. Args: path (string), content (string)\n",
                "- edit: Edit existing file. Args: path (string), content (string)  \n",
                "- read: Read a file. Args: path (string)\n",
                "- bash: Run a command. Args: command (string)\n",
                "\n",
                "## Examples\n",
                "User: \"Create hello.py with print hello world\"\n",
                "```json\n",
                "{\"name\": \"write\", \"arguments\": {\"path\": \"hello.py\", \"content\": \"print('hello world')\"}}\n",
                "```\n",
                "\n",
                "User: \"Run python hello.py\"\n",
                "```json\n",
                "{\"name\": \"bash\", \"arguments\": {\"command\": \"python hello.py\"}}\n",
                "```\n",
                "\n",
                "## For Questions/Greetings\n",
                "Respond naturally with text. Only use tools for file/command operations.'''\n",
                "\n",
                "def needs_tools(msg):\n",
                "    m = msg.lower() if msg else ''\n",
                "    actions = ['create', 'write', 'make', 'generate', 'new', 'save', 'add',\n",
                "               'edit', 'modify', 'update', 'change', 'fix', 'refactor',\n",
                "               'delete', 'remove', 'run', 'execute', 'test', 'build',\n",
                "               'file', 'script', 'code', 'function', 'class']\n",
                "    return any(a in m for a in actions)\n",
                "\n",
                "def get_valid_tools(tools):\n",
                "    return {t['function']['name'] for t in tools or [] if t.get('type') == 'function'}\n",
                "\n",
                "def extract_tool(text, valid):\n",
                "    if not text:\n",
                "        return None\n",
                "    \n",
                "    # Try code block\n",
                "    m = re.search(r'```(?:json)?\\s*([\\s\\S]*?)```', text)\n",
                "    if m:\n",
                "        try:\n",
                "            d = json.loads(m.group(1).strip())\n",
                "            name = d.get('name', '')\n",
                "            if name in valid or not valid:  # Accept if valid list empty or matches\n",
                "                args = d.get('arguments', {})\n",
                "                return name, json.dumps(args) if isinstance(args, dict) else args\n",
                "        except: pass\n",
                "    \n",
                "    # Try raw JSON\n",
                "    m = re.search(r'\\{\\s*\"name\"\\s*:\\s*\"([^\"]+)\"\\s*,\\s*\"arguments\"\\s*:\\s*(\\{[^{}]*\\})', text)\n",
                "    if m:\n",
                "        name = m.group(1)\n",
                "        if name in valid or not valid:\n",
                "            return name, m.group(2)\n",
                "    \n",
                "    return None\n",
                "\n",
                "@app.route('/v1/models', methods=['GET'])\n",
                "def list_models():\n",
                "    return jsonify({\"object\": \"list\", \"data\": [{\"id\": MODEL, \"object\": \"model\"}]})\n",
                "\n",
                "@app.route('/v1/chat/completions', methods=['POST'])\n",
                "def chat():\n",
                "    data = request.json\n",
                "    messages = data.get('messages', [])\n",
                "    tools = data.get('tools', [])\n",
                "    valid_tools = get_valid_tools(tools)\n",
                "    \n",
                "    # Get last user message\n",
                "    user_msg = ''\n",
                "    for m in reversed(messages):\n",
                "        if m.get('role') == 'user' and m.get('content'):\n",
                "            user_msg = str(m['content'])\n",
                "            break\n",
                "    \n",
                "    use_tools = needs_tools(user_msg)\n",
                "    print(f\"[{time.strftime('%H:%M:%S')}] '{user_msg[:40]}' tools={use_tools}\")\n",
                "    \n",
                "    # Build messages\n",
                "    msgs = [{'role': 'system', 'content': TOOL_PROMPT}]\n",
                "    for m in messages:\n",
                "        if m.get('role') != 'system':\n",
                "            msgs.append(m)\n",
                "    \n",
                "    # Call Ollama directly with tools\n",
                "    try:\n",
                "        payload = {\n",
                "            'model': MODEL,\n",
                "            'messages': msgs,\n",
                "            'stream': False,\n",
                "            'options': {'num_ctx': 8192}\n",
                "        }\n",
                "        if use_tools and tools:\n",
                "            payload['tools'] = tools\n",
                "        \n",
                "        r = req.post('http://localhost:11434/api/chat', json=payload, timeout=120)\n",
                "        result = r.json()\n",
                "        content = result.get('message', {}).get('content', '')\n",
                "        native_tools = result.get('message', {}).get('tool_calls', [])\n",
                "    except Exception as e:\n",
                "        print(f\"Error: {e}\")\n",
                "        content = \"I'm ready to help! What would you like me to do?\"\n",
                "        native_tools = []\n",
                "    \n",
                "    # If Ollama returned native tool calls\n",
                "    if native_tools:\n",
                "        formatted = []\n",
                "        for tc in native_tools:\n",
                "            formatted.append({\n",
                "                \"id\": f\"call_{uuid.uuid4().hex[:8]}\",\n",
                "                \"type\": \"function\",\n",
                "                \"function\": {\n",
                "                    \"name\": tc.get('function', {}).get('name', ''),\n",
                "                    \"arguments\": json.dumps(tc.get('function', {}).get('arguments', {}))\n",
                "                }\n",
                "            })\n",
                "        print(f\"  ‚Üí Native tool: {formatted[0]['function']['name']}\")\n",
                "        return jsonify({\n",
                "            \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "            \"object\": \"chat.completion\",\n",
                "            \"created\": int(time.time()),\n",
                "            \"model\": MODEL,\n",
                "            \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": None, \"tool_calls\": formatted}, \"finish_reason\": \"tool_calls\"}],\n",
                "            \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": 50, \"total_tokens\": 150}\n",
                "        })\n",
                "    \n",
                "    # Try to extract tool from text\n",
                "    if use_tools and content:\n",
                "        tool = extract_tool(content, valid_tools)\n",
                "        if tool:\n",
                "            name, args = tool\n",
                "            print(f\"  ‚Üí Parsed tool: {name}\")\n",
                "            return jsonify({\n",
                "                \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "                \"object\": \"chat.completion\",\n",
                "                \"created\": int(time.time()),\n",
                "                \"model\": MODEL,\n",
                "                \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": None, \"tool_calls\": [{\"id\": f\"call_{uuid.uuid4().hex[:8]}\", \"type\": \"function\", \"function\": {\"name\": name, \"arguments\": args}}]}, \"finish_reason\": \"tool_calls\"}],\n",
                "                \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": 50, \"total_tokens\": 150}\n",
                "            })\n",
                "    \n",
                "    # Return text (clean up any stray JSON)\n",
                "    if content:\n",
                "        content = re.sub(r'```json[\\s\\S]*?```', '', content).strip()\n",
                "        content = re.sub(r'\\{\\s*\"name\"[^}]+\\}', '', content).strip()\n",
                "    if not content:\n",
                "        content = \"Hello! I'm ready to help. What would you like me to do?\"\n",
                "    \n",
                "    print(f\"  ‚Üí Text ({len(content)} chars)\")\n",
                "    return jsonify({\n",
                "        \"id\": f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
                "        \"object\": \"chat.completion\",\n",
                "        \"created\": int(time.time()),\n",
                "        \"model\": MODEL,\n",
                "        \"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": content}, \"finish_reason\": \"stop\"}],\n",
                "        \"usage\": {\"prompt_tokens\": 100, \"completion_tokens\": len(content.split()), \"total_tokens\": 100 + len(content.split())}\n",
                "    })\n",
                "\n",
                "threading.Thread(target=lambda: app.run(host='0.0.0.0', port=5000, threaded=True, use_reloader=False), daemon=True).start()\n",
                "time.sleep(2)\n",
                "print(f'\\n‚úÖ Server running!')"
            ],
            "metadata": {
                "id": "api"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üß™ Test\n",
                "import requests\n",
                "\n",
                "# Test tool call\n",
                "print(\"Testing: Create hello.py...\")\n",
                "r = requests.post('http://localhost:5000/v1/chat/completions', json={\n",
                "    'model': 'qwen2.5-coder:7b',\n",
                "    'messages': [{'role': 'user', 'content': 'Create a file called hello.py that prints hello world'}],\n",
                "    'tools': [{'type': 'function', 'function': {'name': 'write', 'description': 'Write file', 'parameters': {'type': 'object', 'properties': {'path': {'type': 'string'}, 'content': {'type': 'string'}}}}}]\n",
                "}, timeout=120)\n",
                "\n",
                "resp = r.json()['choices'][0]\n",
                "if resp['message'].get('tool_calls'):\n",
                "    print(f\"‚úÖ SUCCESS! Tool call: {resp['message']['tool_calls'][0]['function']}\")\n",
                "else:\n",
                "    print(f\"‚ùå Got text instead: {resp['message'].get('content', 'empty')[:100]}\")"
            ],
            "metadata": {
                "id": "test"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üåê Start Tunnel\n",
                "import subprocess, re\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "tunnel = subprocess.Popen(['cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
                "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')\n",
                "    if 'trycloudflare.com' in line:\n",
                "        m = re.search(r'https://[^\\s]+\\.trycloudflare\\.com', line)\n",
                "        if m:\n",
                "            url = m.group()\n",
                "            display(HTML(f'''\n",
                "            <div style=\"background:linear-gradient(135deg,#667eea,#764ba2);padding:30px;border-radius:20px\">\n",
                "                <h2 style=\"color:white;margin:0\">üöÄ OpenCode Ready!</h2>\n",
                "                <p style=\"color:white;font-size:20px;font-family:monospace;margin:15px 0\">{url}/v1</p>\n",
                "                <p style=\"color:#ddd\">Model: qwen2.5-coder:7b (with tool support)</p>\n",
                "            </div>\n",
                "            '''))\n",
                "            break\n",
                "\n",
                "for line in tunnel.stdout:\n",
                "    print(line, end='')"
            ],
            "metadata": {
                "id": "tunnel"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}